{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_dir = Path(\"./captcha_images_v2/\")\n",
    "\n",
    "images = sorted(list(map(str, list(data_dir.glob(\"*.png\")))))\n",
    "labels = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images]\n",
    "characters = set(char for label in labels for char in label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_width = 200\n",
    "img_height = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "downsample_factor = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "max_length = max([len(label) for label in labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Mapping characters to integers\n",
    "char_to_num = layers.StringLookup(vocabulary=list(characters),\n",
    "                                  mask_token=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Mapping integers back to orignial characters\n",
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(),\n",
    "    mask_token=None,\n",
    "    invert=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def split_data(images, labels, train_size=0.9, shuffle=True):\n",
    "    size = len(images)\n",
    "    indices = np.arange(size)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    # 3. Get the size of training samples\n",
    "    train_samples = int(size * train_size)\n",
    "    # 4. Split data into training and validation sets\n",
    "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
    "    x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\n",
    "    return x_train, x_valid, y_train, y_valid\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = split_data(np.array(images),\n",
    "                                                np.array(labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def encode_single_sample(img_path, label):\n",
    "    #1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    #2. Decode and convert it into grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    #3. Convert to float32 in [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    #4. Resize to the desired size.\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    #5. Transpose the image because we want the time\n",
    "    #dimension to correspond to the width of the image.\n",
    "    img = tf.transpose(img, perm=[1,0,2])\n",
    "    #6. Map the characters in label to numbers.\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    #7. Return a dict as our model is expecting two inputs.\n",
    "    return {\"image\":img, \"label\": label}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = (\n",
    "    train_dataset.map(\n",
    "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ef57c8fb",
   "language": "python",
   "display_name": "PyCharm (JA-Experiment)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}